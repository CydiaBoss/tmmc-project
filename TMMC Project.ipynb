{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Group Code\n","\n","Image Processing"],"metadata":{"id":"ekNZNoJHowul"}},{"cell_type":"code","execution_count":2,"metadata":{"cellView":"form","id":"bY7_iS5Hou4p","executionInfo":{"status":"ok","timestamp":1698604235397,"user_tz":240,"elapsed":311,"user":{"displayName":"Andrew Wang","userId":"12090482019312027582"}}},"outputs":[],"source":["# @title Dependencies\n","import os, sys\n","\n","import numpy as np\n","from numpy.typing import NDArray\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import cv2\n","\n","import ipywidgets as widgets\n","from ipywidgets import interact, interact_manual\n","\n","from IPython.display import display, Javascript, Image\n","\n","from google.colab.output import eval_js\n","from base64 import b64decode, b64encode\n","import PIL\n","import io\n","import html\n","import time\n","\n","# function to convert the JavaScript object into an OpenCV image\n","def js_to_image(js_reply):\n","  \"\"\"\n","  Params:\n","          js_reply: JavaScript object containing image from webcam\n","  Returns:\n","          img: OpenCV BGR image\n","  \"\"\"\n","  # decode base64 image\n","  image_bytes = b64decode(js_reply.split(',')[1])\n","  # convert bytes to numpy array\n","  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n","  # decode numpy array into OpenCV BGR image\n","  img = cv2.imdecode(jpg_as_np, flags=1)\n","\n","  return img\n","\n","# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n","def bbox_to_bytes(bbox_array):\n","  \"\"\"\n","  Params:\n","          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n","  Returns:\n","        bytes: Base64 image byte string\n","  \"\"\"\n","  # convert array into PIL image\n","  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n","  iobuf = io.BytesIO()\n","  # format bbox into png for return\n","  bbox_PIL.save(iobuf, format='png')\n","  # format return string\n","  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n","\n","  return bbox_bytes\n","\n","def take_photo(filename='photo.jpg', quality=0.8):\n","  js = Javascript('''\n","    async function takePhoto(quality) {\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      capture.textContent = 'Capture';\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      video.style.display = 'block';\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","      // Wait for Capture to be clicked.\n","      await new Promise((resolve) => capture.onclick = resolve);\n","\n","      const canvas = document.createElement('canvas');\n","      canvas.width = video.videoWidth;\n","      canvas.height = video.videoHeight;\n","      canvas.getContext('2d').drawImage(video, 0, 0);\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","      return canvas.toDataURL('image/jpeg', quality);\n","    }\n","    ''')\n","  display(js)\n","\n","  # get photo data\n","  data = eval_js('takePhoto({})'.format(quality))\n","  # get OpenCV format image\n","  img = js_to_image(data)\n","  # save image\n","  cv2.imwrite(filename, img)\n","\n","  return filename\n","\n","from IPython.display import display, Javascript\n","from google.colab.output import eval_js\n","from base64 import b64decode\n","\n","def re_encode_video(video_path):\n","    print(f\"Re-encoding video, this might take some time, please be patient.\")\n","    #added -r 30, otherwise, for some reason it records 1000FPS as metadata for the Astra\n","    os.system(f\"ffmpeg -y -i {video_path} -vcodec libx264 -r 30 temp.mp4\")\n","    os.system(f\"rm {video_path}\")\n","    os.system(f\"mv temp.mp4 {video_path}\")\n","    print(f\"Done encoding!\")\n","\n","def record_video(filename='video.mp4'):\n","  js = Javascript(\"\"\"\n","    async function recordVideo() {\n","      // mashes together the advanced_outputs.ipynb function provided by Colab,\n","      // a bunch of stuff from Stack overflow, and some sample code from:\n","      // https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API\n","\n","      // Optional frames per second argument.\n","      const options = { mimeType: \"video/webm; codecs=vp9\" };\n","      const div = document.createElement('div');\n","      const capture = document.createElement('button');\n","      const stopCapture = document.createElement(\"button\");\n","      capture.textContent = \"Start Recording\";\n","      capture.style.background = \"green\";\n","      capture.style.color = \"white\";\n","\n","      stopCapture.textContent = \"Stop Recording\";\n","      stopCapture.style.background = \"red\";\n","      stopCapture.style.color = \"white\";\n","      div.appendChild(capture);\n","\n","      const video = document.createElement('video');\n","      const recordingVid = document.createElement(\"video\");\n","      video.style.display = 'block';\n","\n","      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","      // create a media recorder instance, which is an object\n","      // that will let you record what you stream.\n","      let recorder = new MediaRecorder(stream, options);\n","      document.body.appendChild(div);\n","      div.appendChild(video);\n","      // Video is a media element.  This line here sets the object which serves\n","      // as the source of the media associated with the HTMLMediaElement\n","      // Here, we'll set it equal to the stream.\n","      video.srcObject = stream;\n","      // We're inside an async function, so this await will fire off the playing\n","      // of a video. It returns a Promise which is resolved when playback has\n","      // been successfully started. Since this is async, the function will be\n","      // paused until this has started playing.\n","      await video.play();\n","\n","      // Resize the output to fit the video element.\n","      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","      // and now, just wait for the capture button to get clicked in order to\n","      // start recording\n","      await new Promise((resolve) => {\n","        capture.onclick = resolve;\n","      });\n","      recorder.start();\n","      capture.replaceWith(stopCapture);\n","      // use a promise to tell it to stop recording\n","      await new Promise((resolve) => stopCapture.onclick = resolve);\n","      recorder.stop();\n","\n","      let recData = await new Promise((resolve) => recorder.ondataavailable = resolve);\n","      let arrBuff = await recData.data.arrayBuffer();\n","\n","      // stop the stream and remove the video element\n","      stream.getVideoTracks()[0].stop();\n","      div.remove();\n","\n","      let binaryString = \"\";\n","      let bytes = new Uint8Array(arrBuff);\n","      bytes.forEach((byte) => {\n","        binaryString += String.fromCharCode(byte);\n","      })\n","      return btoa(binaryString);\n","    }\n","    \"\"\")\n","  try:\n","    display(js)\n","    data = eval_js('recordVideo({})')\n","    binary = b64decode(data)\n","    with open(filename, \"wb\") as video_file:\n","      video_file.write(binary)\n","    print(\n","        f\"Finished recording video. Saved binary under filename in current working directory: {filename}\"\n","    )\n","    '''\n","    unfortunately, webcam capture is not that clean in Colab and the videos need to\n","    be re-encoded to play properly. This takes some time.\n","    '''\n","    re_encode_video(filename)\n","  except Exception as err:\n","      # In case any exceptions arise\n","      print(str(err))\n","  return filename\n","\n","# JavaScript to properly create our live video stream using our webcam as input\n","def video_stream():\n","  js = Javascript('''\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","\n","    var pendingResolve = null;\n","    var shutdown = false;\n","\n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","\n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","\n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","\n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","\n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","\n","      const instruction = document.createElement('div');\n","      instruction.innerHTML =\n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","\n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","\n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","\n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","\n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","\n","      return {'create': preShow - preCreate,\n","              'show': preCapture - preShow,\n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    ''')\n","\n","  display(js)\n","\n","def video_frame(label, bbox):\n","  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n","  return data"]},{"cell_type":"code","source":["# @title Constant\n","c_nc_cir_min = 0.85 # @param {type:\"slider\", min:0, max:1.01, step:0.01}\n","c_nc_midpt_tol = 1.0 # @param {type:\"slider\", min:0, max:2.01, step:0.01}\n","sample_area = 0.5 # @param {type:\"slider\", min:0, max:1.01, step:0.01}\n","area_filter = True # @param {type:\"boolean\"}\n","\n","min_radius = 15 # @param {type:\"integer\"}\n","max_radius = 200 # @param {type:\"integer\"}\n","\n","min_area = np.pi * (min_radius**2)\n","max_area = np.pi * (max_radius**2)\n","\n","brightness = 10 # @param {type:\"integer\"}\n","contrast = 6 # @param {type:\"integer\"}\n","colour_mode = False # @param {type:\"boolean\"}\n","\n","nc_label = \"NC\"\n","nc_color = (255, 0, 0)\n","c_label = \"C\"\n","c_color = (0, 255, 0)\n","pc_label = \"PC\"\n","pc_color = (0, 0, 225)"],"metadata":{"id":"U2E5U9La0227","cellView":"form","executionInfo":{"status":"ok","timestamp":1698607131713,"user_tz":240,"elapsed":216,"user":{"displayName":"Andrew Wang","userId":"12090482019312027582"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["# @title Main Processing Code\n","def image_process(img : NDArray[np.floating], bbox_array : NDArray[np.floating]=None):\n","    # grayscale image\n","    if colour_mode:\n","        filteredImg = cv2.GaussianBlur(img, (7, 7), 0)\n","        filteredImg = cv2.cvtColor(filteredImg, cv2.COLOR_BGR2GRAY)\n","        filteredImg = cv2.convertScaleAbs(filteredImg, brightness, contrast)\n","        filteredImg = cv2.cvtColor(filteredImg, cv2.COLOR_GRAY2BGR)\n","    else:\n","        filteredImg = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","\n","    # Create Circle Detector\n","    params = cv2.SimpleBlobDetector_Params()\n","\n","    # Filters\n","    params.minThreshold = 1\n","\n","    params.filterByCircularity = True\n","    params.minCircularity = c_nc_cir_min\n","\n","    params.filterByArea = area_filter\n","    params.minArea = min_area\n","    params.maxArea = max_area\n","\n","    detector = cv2.SimpleBlobDetector_create(params)\n","\n","    # Detect blobs in the image\n","    keypoints = detector.detect(filteredImg)\n","    colours = []\n","    sizes = []\n","    for keypoint in keypoints:\n","        total_colour = 0\n","\n","        # Sampling\n","        for y_rg in range(-1, 2):\n","            for x_rg in range(-1, 2):\n","                cl = filteredImg[int(keypoint.pt[1] + y_rg*sample_area), int(keypoint.pt[0] + y_rg*sample_area)]\n","                if colour_mode:\n","                    cl = cl[0]**2\n","                else:\n","                    cl = cl**2\n","                total_colour += cl\n","\n","        total_colour **= (0.5)\n","        colours.append(total_colour)\n","\n","        sizes.append(keypoint.size)\n","\n","    if len(colours) > 0:\n","        middle_c = (max(colours) + min(colours))/2\n","        middle_s = (max(sizes) + min(sizes))/2\n","        i = 0\n","\n","        for keypoint in keypoints:\n","            x = int(keypoint.pt[0])\n","            y = int(keypoint.pt[1])\n","            r = int(keypoint.size / 2)\n","\n","            is_c = sizes[i] >= middle_s * c_nc_midpt_tol if not colour_mode else colours[i] >= middle_c * c_nc_midpt_tol\n","\n","            if is_c:\n","                if bbox_array is None:\n","                    img = cv2.circle(img, (x, y), r, c_color, 2)\n","                    img = cv2.putText(img, c_label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","                else:\n","                    bbox_array = cv2.circle(bbox_array, (x, y), r, c_color, 2)\n","                    bbox_array = cv2.putText(bbox_array, c_label, (x,y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","            else:\n","                if bbox_array is None:\n","                    img = cv2.circle(img, (x, y), r, nc_color, 2)\n","                    img = cv2.putText(img, nc_label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","                else:\n","                    bbox_array = cv2.circle(bbox_array, (x, y), r, nc_color, 2)\n","                    bbox_array = cv2.putText(bbox_array, nc_label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","\n","            i += 1\n","\n","    # Detect Partial\n","    # Create Circle Detector\n","    params = cv2.SimpleBlobDetector_Params()\n","\n","    # Filters\n","    params.minThreshold = 1\n","\n","    params.filterByArea = area_filter\n","    params.minArea = min_area\n","\n","    detector = cv2.SimpleBlobDetector_create(params)\n","\n","    # Detect blobs in the image\n","    pc_keypoints = detector.detect(filteredImg)\n","\n","    # Mark\n","    for pc_keypoint in pc_keypoints:\n","        x = int(pc_keypoint.pt[0])\n","        y = int(pc_keypoint.pt[1])\n","        r = int(pc_keypoint.size / 2)\n","\n","        # Detect Pre-existing Detection\n","        alr_detected = False\n","        for kp in keypoints:\n","            x_k = int(kp.pt[0])\n","            y_k = int(kp.pt[1])\n","            r_k = int(kp.size / 2)\n","\n","            # Detect Bounds\n","            if (x_k + r_k > x and x_k - r_k < x) and (y_k + r_k > y and y_k - y_k < y):\n","                alr_detected = True\n","                break\n","\n","        if alr_detected:\n","            continue\n","\n","        if bbox_array is None:\n","            img = cv2.putText(img, pc_label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","            img = cv2.circle(img, (x, y), r, pc_color, 2)\n","        else:\n","            bbox_array = cv2.putText(bbox_array, pc_label, (x, y), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n","            bbox_array = cv2.circle(bbox_array, (x, y), r, pc_color, 2)\n","\n","    return img, bbox_array, filteredImg\n","\n","def start_live_processing():\n","    # start streaming video from webcam\n","    video_stream()\n","    # label for video\n","    label_html = 'Capturing...'\n","    # initialze bounding box to empty\n","    bbox = ''\n","    count = 0\n","\n","    while True:\n","        js_reply = video_frame(label_html, bbox)\n","        if not js_reply:\n","            break\n","\n","        # convert JS response to OpenCV Image\n","        img = js_to_image(js_reply[\"img\"])\n","\n","        # create transparent overlay for bounding box\n","        bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n","\n","        # Process Image\n","        (img, bbox_array, _) = image_process(img, bbox_array)\n","\n","        bbox_array[:,:,3] = (bbox_array.max(axis = 2) > 0 ).astype(int) * 255\n","        # convert overlay of bbox into bytes\n","        bbox_bytes = bbox_to_bytes(bbox_array)\n","        # update bbox so next frame gets new overlay\n","        bbox = bbox_bytes\n","\n","def static_processing(path_to_img, show_filtered_image=True):\n","    img = cv2.imread(path_to_img)\n","\n","    (img, _, filtered_img) = image_process(img)\n","\n","    plt.figure(figsize=(20,10))\n","    if show_filtered_image:\n","        plt.subplot(1, 2, 1)\n","        plt.imshow(filtered_img),plt.title(f'Blob Map of {path_to_img}',color='c')\n","        plt.subplot(1, 2, 2)\n","    plt.imshow(img),plt.title(f'Result {path_to_img}',color='c')\n","    plt.show()"],"metadata":{"id":"htX2E14LqU6D","cellView":"form","executionInfo":{"status":"ok","timestamp":1698607419421,"user_tz":240,"elapsed":129,"user":{"displayName":"Andrew Wang","userId":"12090482019312027582"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# @title Live Streaming\n","start_live_processing()"],"metadata":{"id":"hX0w1vAMvsC9","cellView":"form","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1698608233359,"user_tz":240,"elapsed":116323,"user":{"displayName":"Andrew Wang","userId":"12090482019312027582"}},"outputId":"509b9825-620f-4b32-a0e6-6a45916810b5"},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    var video;\n","    var div = null;\n","    var stream;\n","    var captureCanvas;\n","    var imgElement;\n","    var labelElement;\n","\n","    var pendingResolve = null;\n","    var shutdown = false;\n","\n","    function removeDom() {\n","       stream.getVideoTracks()[0].stop();\n","       video.remove();\n","       div.remove();\n","       video = null;\n","       div = null;\n","       stream = null;\n","       imgElement = null;\n","       captureCanvas = null;\n","       labelElement = null;\n","    }\n","\n","    function onAnimationFrame() {\n","      if (!shutdown) {\n","        window.requestAnimationFrame(onAnimationFrame);\n","      }\n","      if (pendingResolve) {\n","        var result = \"\";\n","        if (!shutdown) {\n","          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n","          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n","        }\n","        var lp = pendingResolve;\n","        pendingResolve = null;\n","        lp(result);\n","      }\n","    }\n","\n","    async function createDom() {\n","      if (div !== null) {\n","        return stream;\n","      }\n","\n","      div = document.createElement('div');\n","      div.style.border = '2px solid black';\n","      div.style.padding = '3px';\n","      div.style.width = '100%';\n","      div.style.maxWidth = '600px';\n","      document.body.appendChild(div);\n","\n","      const modelOut = document.createElement('div');\n","      modelOut.innerHTML = \"<span>Status:</span>\";\n","      labelElement = document.createElement('span');\n","      labelElement.innerText = 'No data';\n","      labelElement.style.fontWeight = 'bold';\n","      modelOut.appendChild(labelElement);\n","      div.appendChild(modelOut);\n","\n","      video = document.createElement('video');\n","      video.style.display = 'block';\n","      video.width = div.clientWidth - 6;\n","      video.setAttribute('playsinline', '');\n","      video.onclick = () => { shutdown = true; };\n","      stream = await navigator.mediaDevices.getUserMedia(\n","          {video: { facingMode: \"environment\"}});\n","      div.appendChild(video);\n","\n","      imgElement = document.createElement('img');\n","      imgElement.style.position = 'absolute';\n","      imgElement.style.zIndex = 1;\n","      imgElement.onclick = () => { shutdown = true; };\n","      div.appendChild(imgElement);\n","\n","      const instruction = document.createElement('div');\n","      instruction.innerHTML =\n","          '<span style=\"color: red; font-weight: bold;\">' +\n","          'When finished, click here or on the video to stop this demo</span>';\n","      div.appendChild(instruction);\n","      instruction.onclick = () => { shutdown = true; };\n","\n","      video.srcObject = stream;\n","      await video.play();\n","\n","      captureCanvas = document.createElement('canvas');\n","      captureCanvas.width = 640; //video.videoWidth;\n","      captureCanvas.height = 480; //video.videoHeight;\n","      window.requestAnimationFrame(onAnimationFrame);\n","\n","      return stream;\n","    }\n","    async function stream_frame(label, imgData) {\n","      if (shutdown) {\n","        removeDom();\n","        shutdown = false;\n","        return '';\n","      }\n","\n","      var preCreate = Date.now();\n","      stream = await createDom();\n","\n","      var preShow = Date.now();\n","      if (label != \"\") {\n","        labelElement.innerHTML = label;\n","      }\n","\n","      if (imgData != \"\") {\n","        var videoRect = video.getClientRects()[0];\n","        imgElement.style.top = videoRect.top + \"px\";\n","        imgElement.style.left = videoRect.left + \"px\";\n","        imgElement.style.width = videoRect.width + \"px\";\n","        imgElement.style.height = videoRect.height + \"px\";\n","        imgElement.src = imgData;\n","      }\n","\n","      var preCapture = Date.now();\n","      var result = await new Promise(function(resolve, reject) {\n","        pendingResolve = resolve;\n","      });\n","      shutdown = false;\n","\n","      return {'create': preShow - preCreate,\n","              'show': preCapture - preShow,\n","              'capture': Date.now() - preCapture,\n","              'img': result};\n","    }\n","    "]},"metadata":{}}]},{"cell_type":"code","source":["# @title Static Image Procesing\n","show_filtered_image = True # @param {type:\"boolean\"}\n","\n","files = os.listdir(\"./\")\n","files = [f for f in files if os.path.isfile('./' + f) and f.endswith('.jpg')]\n","for i in files:\n","    static_processing(i, show_filtered_image)"],"metadata":{"id":"gWe2x__Rxl8p","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1aU_ZvHBB4k53KJCAYjhTtH4UkVLUU_NS"},"executionInfo":{"status":"ok","timestamp":1698608113912,"user_tz":240,"elapsed":52459,"user":{"displayName":"Andrew Wang","userId":"12090482019312027582"}},"outputId":"7b2694e7-bb0f-470c-c5c6-6d7ef93816f2","cellView":"form"},"execution_count":40,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}